---
title: "f3) Analysis walthrough: 2-way factorial model"
author: "Nathan Brouwer"
date: "`r Sys.Date()`"
output: rmarkdown::pdf_document
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## Introduction

This tutorial walks through some types of analysis that can be done using the shroom package.  In particular it looks at the situation when you have data that can be group by two seperate categorical variables.  In our data, we will look at the impacts of both sex (male vs. female) and experimental group (control vs. mutation to candidation gene) on wing scores.

In the previous tutorial we used t-tests and similar analyses to look at just the impact of mutation ("experimental" flies) on wing scores of the female flies collected by one student, ignoring the males they collected.  In this tutorial we will look at all of the flies collected by the same student.


## Preliminaries

### Load packages


Load the shroom package.  You can download it with instal.packages("shroom") if you haven't used it ever before.  See "Loading the shroom package" for more information.
```{r}
library(shroom)
```

Load other essential packages
```{r}
library(ggpubr)  #plotting
library(cowplot)

library(dplyr)   #data cleaning

library(car)

library(broom)


library(bbmle)   #AIC taBLE
library(lme4)
library(lawstat) #?
library(effsize) #Cohen's dw
```


### Load data

#### Loading data directly from the shroom package

The data are internal to the package and so can be easily loaded.  The wingscores dataset contains data for all flies studnets worked with in 2018.

```{r}
data(wingscores)
```


## Cleaning and subsetting the wing data

This information is covered in more detail in "Subsetting a dataframe with dplyr."

### Examine raw data

```{r}
dim(wingscores)
names(wingscores)
head(wingscores)
```


### Clean the raw data

* Remove some un-needed columns using select().  
* Note "-" before each column name.

```{r select.1}
wingscores <- wingscores %>% select(-stock.num,
                          -loaded,
                          -file,
                          -gene,
                          -temp.C)
```

Data frame now has fewer columns
```{r}
dim(wingscores)
```



## Data analysis: Factorial ANOVA

We will walk through analyses comparing just two groups: female control flies versus female experimental flies.  In subsequent tutorials we'll look at more complex data.

### Nomeclature note: "Student"" vs. "fly-level"" data

Because these data result from summarizing the work done by each student, I will refer to it as **student-level data**.  In contrast, the raw data generated by the student is **fly-level** data because each data point represents a single fly.

### Data from 1 student, including fly sex

We will work with data with 4 groups:

* male experimental
* male control
* female experimental
* female control



Select all data
```{r}
student1.all <- wingscores %>% filter(student.ID ==  1 )
```




#### Structure of the data

We can think of the data like this
```{r, eval = F}
working <- student1.all
working$i <- 1:nrow(working)

i.F.E <- which(working$sex == "F" &
                 working$E.or.C == "E")
i.F.C <- which(working$sex == "F" &
                 working$E.or.C == "C")

i.M.E <- which(working$sex == "M" &
                 working$E.or.C == "E")
i.M.C <- which(working$sex == "M" &
                 working$E.or.C == "C")

i.use <- c(range(working$i[i.F.E])
,range(working$i[i.F.C])
,range(working$i[i.M.E])
,range(working$i[i.M.C]))

i.medians <- round(c(median(working$i[i.F.E])
,median(working$i[i.F.C])
,median(working$i[i.M.E])
,median(working$i[i.M.C])))



working[-i.use, "i"] <- "*\n*\n*"


working$i[which(working$i !=  "*\n*\n*")] <- paste("Fly",working$i[which(working$i !=  "*\n*\n*")])

working$pathString <- with(working,
                              paste(allele,
                                    sex,
                                    E.or.C,
                                    i,
                                    sep = "/"))

i <- sort(c(i.use,i.medians))
working.tree <- as.Node(working[i,])

SetGraphStyle(working.tree,
              rankdir="LR")

plot(working.tree)
     

```


Plot boxplots.  Sex is set as the x axis, and then the two treatments are colored coded using fill =
```{r}
ggboxplot(data = student1.all,
          y = "wing.score",
          x = "sex",
          fill = "E.or.C")
```



For plotting it can be very helpful to make a new variable that combines two seperate colums.

First I'll make the new varible using paste()
```{r}
student1.all$group <- paste(student1.all$sex,
                                 student1.all$E.or.C,
                                 sep = ".")
```

Now I'll recode them using factor() to put things in the order I want.  (Not actually necessary here actually) 
```{r}
student1.all$group <- factor(student1.all$group,
                              levels = c("F.C","F.E",
                                         "M.C","M.E"))
```


Plot with error bars
```{r}
ggerrorplot(data = student1.all,
          y = "wing.score",
          x = "group",
          color = "sex",
          desc_stat = "mean_ci",
          size = 1.2)
```

### Factorial ANOVA

When we have multiple groups that can occcur in combination we can use **factorial** ANOVA.  In this case we have a **2 x 2 ANOVA** because we have two variables, sex and experimental group, with 2 levels.  THat is, each can take on two values: sex = male or female; experimental group (E.or.C) = "E" or "C".

We start with a null model of just the grand mean.  This can also be called and **intercept-only model** because the technical name for this grand mean term in this context is the intercept, and its the only term in teh model, hence intercept-only model.
```{r}
lm.null    <- lm(wing.score ~ 1, data = student1.all)
```

This matches a model set up like this with no x-variable
```{r}
ggerrorplot(data = student1.all,
          y = "wing.score",
          x = NULL,
          color = "sex",
          desc_stat = "mean_ci",
          size = 1.2)
```

THe mean is about 4.7, which we can check with the summary command
```{r}
summary(student1.all$wing.score)
```


Now a model of just sex, ignorning the experimental group.  This model can be written like this.
```{r}
lm.sex     <- lm(wing.score ~ sex, data = student1.all)
```

Technically it has an intercept term plus a term for sex, so the full model is actually this:
```{r}
lm.sex <- lm(wing.score ~ 1+ sex, data = student1.all)
```

R puts in the 1 for the intercept automatically for us.

This model matches the data set up like this:
```{r}
ggerrorplot(data = student1.all,
          y = "wing.score",
          x = "sex",
          color = "sex",
          desc_stat = "mean_ci",
          size = 1.2)
```

We can get the means by hand using dplyr
```{r}
student1.all %>% 
  group_by(sex) %>%
  summarize(mean = mean(wing.score))
```

The next models is for the experimental group, ignoring sex.  Again, R puts the 1 for the intercept in for us automatically.
```{r}
lm.E.or.C  <- lm(wing.score ~ E.or.C,
                 data = student1.all)
```

This model matches the data set up like this:
```{r}
ggerrorplot(data = student1.all,
          y = "wing.score",
          x = "E.or.C",
          color = "E.or.C",
          desc_stat = "mean_ci",
          size = 1.2)
```



Now we can include both at the same time.  I call this an **additive model** because it assumes the effect of one variable is independent of what is going on with the other, so the effects of the experimenta are just added to the effect of being male or feamle.

```{r}
lm.add    <- lm(wing.score ~ sex + E.or.C, data = student1.all)
```

This is actually a bit tricky to graph so we'll leave it alone.

Finally we build a model that includes and **interaction**.  This allows the impact of the experimental treatment to depend on the sex.  We can see this in the graph above: Both male and female control flies (F.C and M.C) are similar.  Female experimental flies are much lower than both F.C and M.C.  In contrast, male experimental flies (M.E) are the highst group.  So, the impact of the experimental treatment causes female flies to get a lower wing score, but male flies to get a higher wing score, relative to controls.

The interaction model can be coded like this.
```{r}
lm.intxn   <- lm(wing.score ~ sex*E.or.C,
                 data = student1.all)
```

To write it out fully, though, we would have to add the additive model used above
```{r, eval = F}
lm.intxn<- lm(wing.score ~ sex + E.or.C + sex*E.or.C,
                 data = student1.all)
```

Actually, if we want to totally write it out we need to include the intercept term of "1"
```{r, eval = F}
lm.intxn<- lm(wing.score ~ 1 + sex + E.or.C + sex*E.or.C,
                 data = student1.all)
```


This corresponds to the first graph we made using our new "group" variable.
```{r}
ggerrorplot(data = student1.all,
          y = "wing.score",
          x = "group",
          color = "sex",
          desc_stat = "mean_ci",
          size = 1.2)
```


We can get the means by hand using dplyr if we pass both sex and E.or.C to group_by
```{r}
student1.all %>% 
  group_by(sex, E.or.C) %>%
  summarize(mean = mean(wing.score))
```


We get teh same results if we use the "group" variable
```{r, eval = F}
student1.all %>% 
  group_by(group) %>%
  summarize(mean = mean(wing.score))
```


##### Model formulas

Its useful to look at all the model formulas at the same time.  I'll use "ws" as a stand-in for wing.scores

Intercept only:    ws ~ 1
sex:               ws ~ 1 + sex
experiment:        ws ~ 1       + E.or.C
additive model:    ws ~ 1 + sex + E.or.C
interaction model: ws ~ 1 + sex + E.or.C + sex*E.or.C

Top to bottom, the models are organized from simplest to most complex in terms of the number of parameters.  We say these models are "nested" because each model  on the list occurs within the model below it.  We would say the Intercept only model is nested within the sex model as well as the experiment model; the sex model and experiment model are both nested within the additive model; and the additive model is nested within the interaction model.  

While the intercept model is also nested within the additive model and interaction model.  Usually, however, we just compare models that differ by a single term.  So we focs on the fact that the intercept and sex models differ by one term (sex) and that the intercept model is the smaller model (1 term, the intercept) nested in teh more complex sex model (2 terms, the intercept and the sex effect). 

### Testing nested models

We can text nested models using the anova() command.  What this does is tests the significance of the term that differs between the 2 models.  

We can compare the sex and the nested null model like this
```{r}
anova(lm.null,
      lm.sex)
```

This tells us that if we are just looking at the sex parameter and ignoring the experimental groups, sex is significanlty different.  DOes this match the graph you made?  Re-run the code to check.

We can do the same for the impact of E.or.C.  Again, this is ignoring sex
```{r}
anova(lm.null,
      lm.E.or.C)
```

This is non-significant.   Does this match the graph you made?  Re-run the graph code if necessary to check. 

We can compare the additive model to what's nested in it, which is both the sex and the E.or.C model.  This is a bit tricky to think about what's going on.  We saw above that sex is significant and E.or.C is not.  So if start with a model with "sex" as a predictor and add "E.or.C" to it, and "E.or.C" on its own isn't significant, then we expect the p-value from this comparisons to be non-significant.  

```{r}
anova(lm.sex, # just sex
      lm.add) # sex + E.or.C
```

In contrast, if we start with the lm.E.or.C model and compar it to lm.add, we are adding "sex" to the model and sex is significant.  So this comparison should be signifcant.
```{r}
anova(lm.E.or.C,
      lm.add)
```

The upshot of comparing these 3 models is that sex is an important predictor of wing score, but E.or.C is not.   This is tricky on the first pass (and probably the 2nd, 3rd and 4th...) but just roll with it for now.


### Interaction model

If we compare the interaction model and the additive model, we are testing the significance of the sex*E.or.C term that is different between them.  Again, the additive model is "sex + E.or.C" while the interaction model is "sex + E.or.C + sex X E.or.C."


```{r}
anova(lm.intxn,
      lm.add)
```

The p-value is small, indicating that there is a significant interaction.  So, while when isolated on its own experimental treatment isn't significant, but when you take into account sex it is.  What this means is the the effect of the "experimental treatment" (mutation of the candidate gene) is different for the two sexes.  For females, E.or.C wing scores are very low, while for males the control and E.or.C means are very similar; if anything, the experimental males are *higher* than controls.

We can quickly see the means of the 4 groups by building a **means model** using -1 notation to "drop the intercept" and using a colon insteads of asterisk between sex and E.or.C (this is just an R thing for coding this type of model).

Build the model
```{r}
lm.means <- lm(wing.score ~ -1 + E.or.C:sex,
                 data = student1.all)
```


Look at the output (I use the tidy() funciton from the broom package to give concise output insteady of the verbosity of summary())
```{r}
tidy(lm.means)
```





### Model comparison using AIC

Another way to look a bunch of models is AIC.  Lower is better. THe best fitting model had a "dAIC" of zero ("d" = "delta" for change.)
```{r}
AICtab(lm.null,
       lm.sex,
       lm.E.or.C,
       lm.add,
       lm.intxn,
       base = TRUE)
```


### Classic ANOVA table

coming soon..


```{r}

```

